{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"term2 sprint12.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"141JTYHdFZMt0uUxSJFb9UkpbbMq8i7bI","authorship_tag":"ABX9TyPY1kY6K0KUPJD+nacweh4d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kYFoam5vK-8R"},"source":["【問題1】スクラッチを振り返る"]},{"cell_type":"markdown","metadata":{"id":"u-xmbtcsK-4w"},"source":["●ディープラーニングを実装するためにはどのようなものが必要だったかを列挙\n","\n","・重みを初期化する必要があった  \n","・エポックのループが必要だった  \n","・入力層、隠れ層、出力層が必要だった  \n","・フォワードプロバゲーション、交差エントロピー、バックプロバゲーションの計算が必要だった  \n","・活性化関数が必要だった  \n","・ミニバッチ処理の確率的勾配降下法を行った  \n","など"]},{"cell_type":"markdown","metadata":{"id":"pTQx-tuPK-xo"},"source":["【問題2】スクラッチとTensorFlowの対応を考える"]},{"cell_type":"markdown","metadata":{"id":"3gPLslEZK-m9"},"source":["・エポックのループが必要だった  \n","・ミニバッチ処理の確率的勾配降下法を行った   \n","for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train)  \n","with tf.GradientTape() as tape  \n","という方法で行っている\n","\n","・重みを初期化する必要があった  \n","self.w1 = tf.Variable(tf.random.normal([n_input, n_hidden1]), trainable=True)  \n","このようにVariableの中で、tf.random.normalというメソッドを使用して初期化を行っている\n","\n","・入力層、隠れ層、出力層が必要だった  \n","def call(self, x)の中で単純な3層ニューラルネットワークを構築している\n","\n","・フォワードプロバゲーション、交差エントロピー、バックプロバゲーションの計算が必要だった \n","def train(x, y)の中で、model = MyModel()宣言したもので定義し、それを計算グラフの実行のループの中で行っている\n","\n","・活性化関数が必要だった  \n","layer_1 = tf.nn.relu(layer_1)で使用、ここでは　Relu関数を活性化関数と使用している"]},{"cell_type":"markdown","metadata":{"id":"d2MTYXhkLLup"},"source":["【問題3】3種類すべての目的変数を使用したIrisのモデルを作成"]},{"cell_type":"markdown","metadata":{"id":"mpDTvXPfLSXP"},"source":["まずテキストのサンプルコードを実行する"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tka86u3YDhIC","executionInfo":{"status":"ok","timestamp":1629445136894,"user_tz":-540,"elapsed":874,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}},"outputId":"7b6616a3-6f03-4219-a5ef-9ddd242f7bfd"},"source":["\"\"\"\n","TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","# データセットの読み込み\n","dataset_path =\"/content/sample_data/Iris.csv\"\n","df = pd.read_csv(dataset_path)\n","# データフレームから条件抽出\n","df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n","y = df[\"Species\"]\n","X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","y = np.array(y)\n","X = np.array(X).astype(np.float32)\n","# ラベルを数値に変換\n","y[y=='Iris-versicolor'] = 0\n","y[y=='Iris-virginica'] = 1\n","y = y.astype(np.float32)[:, np.newaxis]\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","class GetMiniBatch:\n","    \"\"\"\n","    ミニバッチを取得するイテレータ\n","    Parameters\n","    ----------\n","    X : 次の形のndarray, shape (n_samples, n_features)\n","      訓練データ\n","    y : 次の形のndarray, shape (n_samples, 1)\n","      正解値\n","    batch_size : int\n","      バッチサイズ\n","    seed : int\n","      NumPyの乱数のシード\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","    def __len__(self):\n","        return self._stop\n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","# ハイパーパラメータの設定\n","learning_rate = 0.01\n","batch_size = 10\n","num_epochs = 10\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = 1\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","\n","class MyModel(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        # 重みとバイアスの宣言\n","        self.w1 = tf.Variable(tf.random.normal([n_input, n_hidden1]), trainable=True)\n","        self.w2 = tf.Variable(tf.random.normal([n_hidden1, n_hidden2]), trainable=True)\n","        self.w3 = tf.Variable(tf.random.normal([n_hidden2, n_classes]), trainable=True)\n","        self.b1 = tf.Variable(tf.random.normal([n_hidden1]), trainable=True)\n","        self.b2 = tf.Variable(tf.random.normal([n_hidden2]), trainable=True)\n","        self.b3 = tf.Variable(tf.random.normal([n_classes]), trainable=True)\n","    def call(self, x):\n","        \"\"\"\n","        単純な3層ニューラルネットワーク\n","        \"\"\"\n","        layer_1 = tf.add(tf.matmul(x, self.w1), self.b1)\n","        layer_1 = tf.nn.relu(layer_1)\n","        layer_2 = tf.add(tf.matmul(layer_1, self.w2), self.b2)\n","        layer_2 = tf.nn.relu(layer_2)\n","        layer_output = tf.matmul(layer_2, self.w3) + self.b3  # tf.addと+は等価である\n","        return layer_output\n","model = MyModel()\n","\n","# # 最適化手法\n","optimizer = tf.keras.optimizers.Adam(learning_rate)\n","\n","def train(x, y):\n","    logits = model(x, training=True)\n","    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","    return loss\n","\n","def evaluate(x, y):\n","    logits = model(x)\n","    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","    # 推定結果\n","    correct_pred = tf.equal(tf.sign(y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","    # 指標値計算\n","    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","    return loss, accuracy\n","\n","# 計算グラフの実行\n","for epoch in range(num_epochs):\n","    # エポックごとにループ\n","    total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","    total_loss = 0\n","    total_acc = 0\n","    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","        # ミニバッチごとにループ\n","        with tf.GradientTape() as tape:\n","            loss = train(mini_batch_x, mini_batch_y)\n","        grads = tape.gradient(loss, model.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","        total_loss += loss\n","    loss = total_loss / n_samples\n","    val_loss, val_acc = evaluate(X_val, y_val)\n","    print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, val_acc))\n","_, test_acc = evaluate(X_test, y_test)\n","print(\"test_acc : {:.3f}\".format(test_acc))"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Epoch 0, loss : 2.8938, val_loss : 24.8592, val_acc : 0.625\n","Epoch 1, loss : 2.1616, val_loss : 3.6878, val_acc : 0.812\n","Epoch 2, loss : 0.1475, val_loss : 3.2928, val_acc : 0.875\n","Epoch 3, loss : 0.1420, val_loss : 8.7232, val_acc : 0.688\n","Epoch 4, loss : 0.5042, val_loss : 4.1795, val_acc : 0.750\n","Epoch 5, loss : 0.1158, val_loss : 9.3707, val_acc : 0.688\n","Epoch 6, loss : 0.4725, val_loss : 2.8216, val_acc : 0.750\n","Epoch 7, loss : 0.0656, val_loss : 9.7296, val_acc : 0.688\n","Epoch 8, loss : 0.4804, val_loss : 4.5200, val_acc : 0.812\n","Epoch 9, loss : 0.1107, val_loss : 12.1606, val_acc : 0.688\n","test_acc : 0.750\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G5288-YeK9xq"},"source":["テキストのコードは問題なく実行されている\n","\n","これを３値分類に拡張する"]},{"cell_type":"code","metadata":{"id":"wyeA6XLPM2CI","executionInfo":{"status":"ok","timestamp":1629441029281,"user_tz":-540,"elapsed":224,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}}},"source":["#　まずOneHotEncoderを実行\n","# データセットの読み込み\n","dataset_path =\"/content/sample_data/Iris.csv\"\n","df = pd.read_csv(dataset_path)\n","# データフレームから条件抽出\n","#df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n","y = df[\"Species\"]\n","X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","y = np.array(y)\n","X = np.array(X).astype(np.float32)\n","y[y=='Iris-setosa'] = 0\n","y[y=='Iris-versicolor'] = 1\n","y[y=='Iris-virginica'] = 2\n","y = y.astype(np.float32)[:, np.newaxis]\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBqPQU_SOAgt","executionInfo":{"status":"ok","timestamp":1629441031143,"user_tz":-540,"elapsed":249,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}}},"source":["#　OneHotEncoderを実行\n","y_train_hot=y_train.reshape(-1,)\n","y_val_hot=y_val.reshape(-1,)\n","y_test_hot=y_test.reshape(-1,)\n","from sklearn.preprocessing import OneHotEncoder\n","enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n","y_train_one_hot = enc.fit_transform(y_train_hot[:, np.newaxis])\n","y_val_one_hot = enc.transform(y_val_hot[:, np.newaxis])\n","y_test_one_hot = enc.transform(y_test_hot[:, np.newaxis])"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3VLhLdFkPGZP","executionInfo":{"status":"ok","timestamp":1629445177764,"user_tz":-540,"elapsed":826,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}},"outputId":"44605f91-66b4-41a2-d456-cc0b8a394122"},"source":["class GetMiniBatch:\n","    \"\"\"\n","    ミニバッチを取得するイテレータ\n","    Parameters\n","    ----------\n","    X : 次の形のndarray, shape (n_samples, n_features)\n","      訓練データ\n","    y : 次の形のndarray, shape (n_samples, 1)\n","      正解値\n","    batch_size : int\n","      バッチサイズ\n","    seed : int\n","      NumPyの乱数のシード\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","    def __len__(self):\n","        return self._stop\n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","# ハイパーパラメータの設定\n","learning_rate = 0.01\n","batch_size = 10\n","num_epochs = 10\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = 1\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","\n","class MyModel(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        # 重みとバイアスの宣言\n","        self.w1 = tf.Variable(tf.random.normal([n_input, n_hidden1]), trainable=True)\n","        self.w2 = tf.Variable(tf.random.normal([n_hidden1, n_hidden2]), trainable=True)\n","        self.w3 = tf.Variable(tf.random.normal([n_hidden2, n_classes]), trainable=True)\n","        self.b1 = tf.Variable(tf.random.normal([n_hidden1]), trainable=True)\n","        self.b2 = tf.Variable(tf.random.normal([n_hidden2]), trainable=True)\n","        self.b3 = tf.Variable(tf.random.normal([n_classes]), trainable=True)\n","    def call(self, x):\n","        \"\"\"\n","        単純な3層ニューラルネットワーク\n","        \"\"\"\n","        layer_1 = tf.add(tf.matmul(x, self.w1), self.b1)\n","        layer_1 = tf.nn.relu(layer_1)\n","        layer_2 = tf.add(tf.matmul(layer_1, self.w2), self.b2)\n","        layer_2 = tf.nn.relu(layer_2)\n","        layer_output = tf.matmul(layer_2, self.w3) + self.b3  # tf.addと+は等価である\n","        return layer_output\n","model = MyModel()\n","\n","# # 最適化手法\n","optimizer = tf.keras.optimizers.Adam(learning_rate)\n","\n","def train(x, y):\n","    logits = model(x, training=True)\n","    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","    return loss\n","\n","def evaluate(x, y):\n","    logits = model(x)\n","    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","    # 推定結果\n","    correct_pred = tf.equal(tf.sign(y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","    # 指標値計算\n","    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","    return loss, accuracy\n","\n","# 計算グラフの実行\n","for epoch in range(num_epochs):\n","    # エポックごとにループ\n","    total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","    total_loss = 0\n","    total_acc = 0\n","    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","        # ミニバッチごとにループ\n","        with tf.GradientTape() as tape:\n","            loss = train(mini_batch_x, mini_batch_y)\n","        grads = tape.gradient(loss, model.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","        total_loss += loss\n","    loss = total_loss / n_samples\n","    val_loss, val_acc = evaluate(X_val, y_val)\n","    print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, val_acc))\n","_, test_acc = evaluate(X_test, y_test)\n","print(\"test_acc : {:.3f}\".format(test_acc))"],"execution_count":53,"outputs":[{"output_type":"stream","text":["Epoch 0, loss : 7.6084, val_loss : 26.8033, val_acc : 0.375\n","Epoch 1, loss : 1.4488, val_loss : 11.2521, val_acc : 0.375\n","Epoch 2, loss : 0.1715, val_loss : 0.2017, val_acc : 0.875\n","Epoch 3, loss : 0.0371, val_loss : 0.9877, val_acc : 0.875\n","Epoch 4, loss : 0.1147, val_loss : 0.0000, val_acc : 1.000\n","Epoch 5, loss : 0.0548, val_loss : 0.0009, val_acc : 1.000\n","Epoch 6, loss : 0.0111, val_loss : 0.3969, val_acc : 0.875\n","Epoch 7, loss : 0.0730, val_loss : 0.0001, val_acc : 1.000\n","Epoch 8, loss : 0.0545, val_loss : 0.1121, val_acc : 0.938\n","Epoch 9, loss : 0.0195, val_loss : 0.4401, val_acc : 0.938\n","test_acc : 0.850\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OhWAFUORZ4QI"},"source":["【問題4】House Pricesのモデルを作成"]},{"cell_type":"code","metadata":{"id":"CCiWw8njQQFF","executionInfo":{"status":"ok","timestamp":1629462493388,"user_tz":-540,"elapsed":328,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}}},"source":["# PandasのDataFrame型のtrain_dataに格納\n","import pandas as pd\n","import numpy as np\n","\n","train_data=pd.read_csv(\"/content/sample_data/train.csv\")"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"XwYoZdF8aNGW","executionInfo":{"status":"ok","timestamp":1629462498067,"user_tz":-540,"elapsed":302,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}}},"source":["X =train_data.loc[:,['GrLivArea','YearBuilt']]\n","y =train_data.loc[:,\"SalePrice\"]\n","X_np=np.array(X)\n","X_np=X_np.astype(float)\n","y_np=np.array(y)\n","\n","# データ分割\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = train_test_split(X_np, y_np,test_size=0.25,random_state=0)\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kjVnaWYiJGk","executionInfo":{"status":"ok","timestamp":1629462916615,"user_tz":-540,"elapsed":747,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}},"outputId":"c00a62a3-74ad-420b-88a7-109949686330"},"source":["\"\"\"\n","TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","# データセットの読み込み\n","dataset_path =\"/content/sample_data/Iris.csv\"\n","df = pd.read_csv(dataset_path)\n","# データフレームから条件抽出\n","df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n","y = df[\"Species\"]\n","X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","y = np.array(y)\n","X = np.array(X).astype(np.float32)\n","# ラベルを数値に変換\n","y[y=='Iris-versicolor'] = 0\n","y[y=='Iris-virginica'] = 1\n","y = y.astype(np.float32)[:, np.newaxis]\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","class GetMiniBatch:\n","    \"\"\"\n","    ミニバッチを取得するイテレータ\n","    Parameters\n","    ----------\n","    X : 次の形のndarray, shape (n_samples, n_features)\n","      訓練データ\n","    y : 次の形のndarray, shape (n_samples, 1)\n","      正解値\n","    batch_size : int\n","      バッチサイズ\n","    seed : int\n","      NumPyの乱数のシード\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","    def __len__(self):\n","        return self._stop\n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","# ハイパーパラメータの設定\n","learning_rate = 0.01\n","batch_size = 10\n","num_epochs = 10\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = 1\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","\n","class MyModel(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        # 重みとバイアスの宣言\n","        self.w1 = tf.Variable(tf.random.normal([n_input, n_hidden1]), trainable=True)\n","        self.w2 = tf.Variable(tf.random.normal([n_hidden1, n_hidden2]), trainable=True)\n","        self.w3 = tf.Variable(tf.random.normal([n_hidden2, n_classes]), trainable=True)\n","        self.b1 = tf.Variable(tf.random.normal([n_hidden1]), trainable=True)\n","        self.b2 = tf.Variable(tf.random.normal([n_hidden2]), trainable=True)\n","        self.b3 = tf.Variable(tf.random.normal([n_classes]), trainable=True)\n","    def call(self, x):\n","        \"\"\"\n","        単純な3層ニューラルネットワーク\n","        \"\"\"\n","        layer_1 = tf.add(tf.matmul(x, self.w1), self.b1)\n","        layer_1 = tf.nn.relu(layer_1)\n","        layer_2 = tf.add(tf.matmul(layer_1, self.w2), self.b2)\n","        layer_2 = tf.nn.relu(layer_2)\n","        layer_output = tf.matmul(layer_2, self.w3) + self.b3  # tf.addと+は等価である\n","        return layer_output\n","model = MyModel()\n","\n","# # 最適化手法\n","optimizer = tf.keras.optimizers.Adam(learning_rate)\n","\n","def train(x, y):\n","    logits = model(x, training=True)\n","    loss=tf.reduce_mean(tf.math.squared_difference(y,logits))\n","    #loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y,logits))\n","    return loss\n","\n","def evaluate(x, y):\n","    logits = model(x)\n","    loss=tf.reduce_mean(tf.math.squared_difference(y,logits))\n","    # 推定結果\n","    #correct_pred = tf.equal(tf.sign(y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","    # 指標値計算\n","    #accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","    return loss\n","\n","# 計算グラフの実行\n","for epoch in range(num_epochs):\n","    # エポックごとにループ\n","    total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","    total_loss = 0\n","    total_acc = 0\n","    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","        # ミニバッチごとにループ\n","        with tf.GradientTape() as tape:\n","            loss = train(mini_batch_x, mini_batch_y)   \n","        grads = tape.gradient(loss, model.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","        total_loss += loss\n","    loss = total_loss / n_samples\n","    val_loss = evaluate(X_val, y_val)\n","    print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}\".format(epoch, loss, val_loss))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 0, loss : 526.6512, val_loss : 1983.8151\n","Epoch 1, loss : 112.9508, val_loss : 734.5415\n","Epoch 2, loss : 60.1161, val_loss : 101.7533\n","Epoch 3, loss : 31.8579, val_loss : 68.2061\n","Epoch 4, loss : 10.4862, val_loss : 109.6840\n","Epoch 5, loss : 12.6958, val_loss : 30.5900\n","Epoch 6, loss : 5.1720, val_loss : 28.1490\n","Epoch 7, loss : 2.3097, val_loss : 10.2539\n","Epoch 8, loss : 1.7250, val_loss : 8.0759\n","Epoch 9, loss : 2.0552, val_loss : 5.4345\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wItN8RBxj8g8"},"source":["回帰問題のため、正解率は削除して、lossのみを表示した  \n","回帰問題でもサンプルコードを一部修正し実装することができた"]},{"cell_type":"markdown","metadata":{"id":"v8-E1JzFkSxI"},"source":["【問題5】MNISTのモデルを作成"]},{"cell_type":"code","metadata":{"id":"SBXfxLgHiJO8","executionInfo":{"status":"ok","timestamp":1629463399530,"user_tz":-540,"elapsed":328,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}}},"source":["# データの取り込みと前処理\n","\n","#　データの取り込みと処理を行う\n","import numpy as np\n","import math \n","from keras.datasets import mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"rB8Rc1TRiJRS","executionInfo":{"status":"ok","timestamp":1629463401612,"user_tz":-540,"elapsed":3,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}}},"source":["X_train = X_train.reshape(-1, 784)\n","X_test = X_test.reshape(-1, 784)\n","X_train = X_train.astype(np.float)\n","X_test = X_test.astype(np.float)\n","X_train /= 255\n","X_test /= 255"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"XB1KiyKOlkOr","executionInfo":{"status":"ok","timestamp":1629463410571,"user_tz":-540,"elapsed":300,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}}},"source":["from sklearn.preprocessing import OneHotEncoder\n","enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n","y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n","y_test_one_hot = enc.transform(y_test[:, np.newaxis])"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxYmxzfllI_9","executionInfo":{"status":"ok","timestamp":1629463447325,"user_tz":-540,"elapsed":332,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.20)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nQUlFGpTiMhI","executionInfo":{"status":"ok","timestamp":1629464694659,"user_tz":-540,"elapsed":295240,"user":{"displayName":"千田康弘","photoUrl":"","userId":"12898088032703686284"}},"outputId":"1f60ecff-5bcf-4bce-d293-78795769f641"},"source":["class GetMiniBatch:\n","    \"\"\"\n","    ミニバッチを取得するイテレータ\n","    Parameters\n","    ----------\n","    X : 次の形のndarray, shape (n_samples, n_features)\n","      訓練データ\n","    y : 次の形のndarray, shape (n_samples, 1)\n","      正解値\n","    batch_size : int\n","      バッチサイズ\n","    seed : int\n","      NumPyの乱数のシード\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","    def __len__(self):\n","        return self._stop\n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","# ハイパーパラメータの設定\n","learning_rate = 0.01\n","batch_size = 10\n","num_epochs = 10\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = 10\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","\n","class MyModel(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        # 重みとバイアスの宣言\n","        self.w1 = tf.Variable(tf.random.normal([n_input, n_hidden1]), trainable=True)\n","        self.w2 = tf.Variable(tf.random.normal([n_hidden1, n_hidden2]), trainable=True)\n","        self.w3 = tf.Variable(tf.random.normal([n_hidden2, n_classes]), trainable=True)\n","        self.b1 = tf.Variable(tf.random.normal([n_hidden1]), trainable=True)\n","        self.b2 = tf.Variable(tf.random.normal([n_hidden2]), trainable=True)\n","        self.b3 = tf.Variable(tf.random.normal([n_classes]), trainable=True)\n","    def call(self, x):\n","        \"\"\"\n","        単純な3層ニューラルネットワーク\n","        \"\"\"\n","        layer_1 = tf.add(tf.matmul(x, self.w1), self.b1)\n","        layer_1 = tf.nn.relu(layer_1)\n","        layer_2 = tf.add(tf.matmul(layer_1, self.w2), self.b2)\n","        layer_2 = tf.nn.relu(layer_2)\n","        layer_output = tf.matmul(layer_2, self.w3) + self.b3  # tf.addと+は等価である\n","        return layer_output\n","model = MyModel()\n","\n","# # 最適化手法\n","optimizer = tf.keras.optimizers.Adam(learning_rate)\n","\n","def train(x, y):\n","    logits = model(x, training=True)\n","    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, logits))\n","    #loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","    return loss\n","\n","def evaluate(x, y):\n","    logits = model(x)\n","    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, logits))\n","    #loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y, logits))\n","    # 推定結果\n","    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(logits,1))\n","    #correct_pred = tf.equal(tf.sign(y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","    # 指標値計算\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n","    #accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","    return loss, accuracy\n","\n","# 計算グラフの実行\n","for epoch in range(num_epochs):\n","    # エポックごとにループ\n","    total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","    total_loss = 0\n","    total_acc = 0\n","    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","        # ミニバッチごとにループ\n","        with tf.GradientTape() as tape:\n","            loss = train(mini_batch_x, mini_batch_y)\n","        grads = tape.gradient(loss, model.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","        total_loss += loss\n","    loss = total_loss / n_samples\n","    val_loss, val_acc = evaluate(X_val, y_val)\n","    print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, val_acc))\n","_, test_acc = evaluate(X_test, y_test_one_hot)\n","print(\"test_acc : {:.3f}\".format(test_acc))"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Epoch 0, loss : 0.5732, val_loss : 0.9656, val_acc : 0.746\n","Epoch 1, loss : 0.0898, val_loss : 1.0207, val_acc : 0.814\n","Epoch 2, loss : 0.0576, val_loss : 0.4219, val_acc : 0.895\n","Epoch 3, loss : 0.0375, val_loss : 0.3347, val_acc : 0.919\n","Epoch 4, loss : 0.0316, val_loss : 0.2832, val_acc : 0.928\n","Epoch 5, loss : 0.0300, val_loss : 0.3201, val_acc : 0.925\n","Epoch 6, loss : 0.0292, val_loss : 0.3002, val_acc : 0.928\n","Epoch 7, loss : 0.0274, val_loss : 0.3257, val_acc : 0.930\n","Epoch 8, loss : 0.0273, val_loss : 0.3367, val_acc : 0.933\n","Epoch 9, loss : 0.0275, val_loss : 0.3215, val_acc : 0.933\n","test_acc : 0.934\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"00VXHFu2iMZf"},"source":[""],"execution_count":null,"outputs":[]}]}