{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Conv d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "#チェック用データ取り込み\n",
    "\n",
    "import numpy as np\n",
    "# フォワードプロバケーション\n",
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "# a = np.array([35, 50])\n",
    "\n",
    "# バックプロバケーション\n",
    "delta_a = np.array([10, 20])\n",
    "# delta_b = np.array([30])\n",
    "# delta_w = np.array([50, 80, 110])\n",
    "# delta_x = np.array([30, 110, 170, 140])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テスト実行例（復習用に残してます）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　フォワードプロバケション\n",
    "fp=np.zeros(w.shape[0]-1)\n",
    "for i in range(w.shape[0]-1):\n",
    "    total=0\n",
    "    for s in range(w.shape[0]):\n",
    "        total+=x[i+s]*w[s]\n",
    "    fp[i]=(total+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35., 50.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　バックプロバケーション\n",
    "dw=np.zeros(w.shape[0])\n",
    "db=np.sum(delta_a)\n",
    "for s in range(w.shape[0]):\n",
    "    total=0\n",
    "    for i in range(fp.shape[0]):\n",
    "        total+=delta_a[i]*x[i+s]\n",
    "    dw[s]=total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 50.,  80., 110.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前の層に流す誤差\n",
    "dx=np.zeros(x.shape[0])\n",
    "for j in range(x.shape[0]):\n",
    "    total=0\n",
    "    for s in range(w.shape[0]):\n",
    "        if not(j-s<0 or j-s>fp.shape[0]-1):\n",
    "            total+=delta_a[j-s]*w[s]\n",
    "        else :\n",
    "            total+=0\n",
    "    dx[j]=total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 30., 110., 170., 140.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d: \n",
    "    \n",
    "    def __init__(self,n_nodes1, n_nodes2,initializer,optimizer,lr):        \n",
    "        self.lr=lr      \n",
    "        self.n_nodes1=n_nodes1\n",
    "        self.n_nodes2=n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.W1=self.initializer.W(self.n_nodes1,self.n_nodes2)\n",
    "        self.B1=self.initializer.B(self.n_nodes2)        \n",
    "        self.optimizer = optimizer\n",
    "        self.A=np.zeros(self.W1.shape[0]-1) \n",
    "        \n",
    "    def forward(self, X):\n",
    "        A=np.zeros(self.W1.shape[0]-1) \n",
    "        for i in range(self.W1.shape[0]-1):\n",
    "            total=0\n",
    "            for s in range(self.W1.shape[0]):\n",
    "                total+=X[i+s]*self.W1[s]\n",
    "            A[i]=(total+self.B1)\n",
    "            self.A=A\n",
    "        return A\n",
    "    \n",
    "    def backward(self,X):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # self.totalはソフトマックス関数の中の交差エントロピー\n",
    "        \n",
    "        self.DW1=np.zeros(self.W1.shape[0])\n",
    "        self.DB1=np.sum(self.total)\n",
    "        for s in range(self.total.shape[0]):\n",
    "            total=0\n",
    "            for i in range(self.A.shape[0]):\n",
    "                total+=self.total[i]*X[i+s]\n",
    "            self.DW1[s]=total\n",
    "            \n",
    "        dX=np.zeros(X.shape[0])\n",
    "        for j in range(X.shape[0]):\n",
    "            total=0\n",
    "            for s in range(self.W1.shape[0]):\n",
    "                if not(j-s<0 or j-s>self.A.shape[0]-1):\n",
    "                    total+=self.total[j-s]*self.self.W1[s]\n",
    "                else :\n",
    "                    total+=0\n",
    "            dX[j]=total\n",
    "\n",
    "        # 更新\n",
    "        self.B1 = self.B1-self.lr*self.DB1\n",
    "        self.W1 = self.W1-self.lr*self.DW1\n",
    "    \n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題2】1次元畳み込み後の出力サイズの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_output(Nin,P,F,S):\n",
    "    \"\"\"\n",
    "    Nin : 入力のサイズ（特徴量の数）\n",
    "    P : ある方向へのパディングの数\n",
    "    F : フィルタのサイズ\n",
    "    S : ストライドのサイズ   \n",
    "    \"\"\"\n",
    "    N_out=((Nin+2*P-F)/S)+1\n",
    "    return N_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題3】小さな配列での1次元畳み込み層の実験(問題１のクラスをサンプル出力用に少し書き換えた)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d: \n",
    "    \n",
    "    def __init__(self,lr):        \n",
    "        self.lr=lr      \n",
    "        \n",
    "    def forward(self, X,W,B):\n",
    "        A=np.zeros(W.shape[0]-1) \n",
    "        for i in range(W.shape[0]-1):\n",
    "            total=0\n",
    "            for s in range(W.shape[0]):\n",
    "                total+=X[i+s]*W[s]\n",
    "            A[i]=(total+B)\n",
    "            self.A=A\n",
    "        return A\n",
    "    \n",
    "    def backward(self,X,W,B,delta_a):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # self.totalはソフトマックス関数の中の交差エントロピー\n",
    "        \n",
    "        self.DW1=np.zeros(W.shape[0])\n",
    "        self.DB1=np.array(np.sum(delta_a))\n",
    "        for s in range(W.shape[0]):\n",
    "            total=0\n",
    "            for i in range(self.A.shape[0]):\n",
    "                total+=delta_a[i]*X[i+s]\n",
    "            self.DW1[s]=total\n",
    "            \n",
    "        dX=np.zeros(X.shape[0])\n",
    "        for j in range(X.shape[0]):\n",
    "            total=0\n",
    "            for s in range(W.shape[0]):\n",
    "                if not(j-s<0 or j-s>self.A.shape[0]-1):\n",
    "                    total+=delta_a[j-s]*W[s]\n",
    "                else :\n",
    "                    total+=0\n",
    "            dX[j]=total\n",
    "\n",
    "        # 更新\n",
    "        self.B1 = B-self.lr*self.DB1\n",
    "        self.W1 = W-self.lr*self.DW1\n",
    "    \n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,2,3,4])\n",
    "W = np.array([3, 5, 7])\n",
    "B = np.array([1])\n",
    "delta_a = np.array([10, 20])\n",
    "lr=0.01\n",
    "SC1=SimpleConv1d(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35., 50.])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# フォワードプロバケーションを出力、テキストに書いてある期待される値と同じになった\n",
    "SC1.forward(X,W,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30. 110. 170. 140.]\n",
      "[ 50.  80. 110.]\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# バックプロバケーションを出力、テキストに書いてある期待される値と同じになった\n",
    "print(SC1.backward(X,W,B,delta_a))\n",
    "print(SC1.DW1)\n",
    "print(SC1.DB1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ取り込み\n",
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) \n",
    "w = np.ones((3, 2, 3)) \n",
    "b = np.array([1, 2, 3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　出力の特徴量の数\n",
    "N_out=size_output(4,0,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　仮の実行サンプル\n",
    "fp=np.zeros(int(N_out)*w.shape[0])\n",
    "fp1=fp.reshape(w.shape[0],int(N_out))\n",
    "list_a=[]\n",
    "#list_a=np.array(list_a)\n",
    "\n",
    "for k in range(w.shape[0]):\n",
    "    list_a=[]\n",
    "    list_a=np.array(list_a)\n",
    "    for j in range(w.shape[0]-1):\n",
    "        for i in range(int(N_out)):\n",
    "            total=0\n",
    "            for s in range(w.shape[2]):\n",
    "                total+=x[j,i+s]*w[j,i,s]\n",
    "            list_a=np.append(list_a,total)\n",
    "        list_a=list_a.reshape(-1,int(N_out))\n",
    "        list_a=np.sum(list_a,axis=0)\n",
    "    fp1[k,:]=list_a+b[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 22.],\n",
       "       [17., 23.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#　テキストにて期待される値が返ってきていることがわかった、これをクラス化させる\n",
    "fp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d_A: \n",
    "    \n",
    "    def __init__(self,lr):        \n",
    "        self.lr=lr      \n",
    "        \n",
    "    def forward(self, X,W,B):\n",
    "        N_out=size_output(X.shape[1],0,W.shape[2],1)\n",
    "        \n",
    "        \n",
    "        fp=np.zeros(int(N_out)*W.shape[0])\n",
    "        A=fp.reshape(W.shape[0],int(N_out))\n",
    "\n",
    "        for k in range(W.shape[0]):\n",
    "            list_a=[]\n",
    "            list_a=np.array(list_a)\n",
    "            for j in range(W.shape[0]-1):\n",
    "                for i in range(int(N_out)):\n",
    "                    total=0\n",
    "                    for s in range(W.shape[2]):\n",
    "                        total+=X[j,i+s]*W[j,i,s]\n",
    "                    list_a=np.append(list_a,total)\n",
    "                list_a=list_a.reshape(-1,int(N_out))\n",
    "                list_a=np.sum(list_a,axis=0)\n",
    "            A[k,:]=list_a+b[k]\n",
    "            self.A=A\n",
    "\n",
    "        return A\n",
    "    \n",
    "    def backward(self,X,W,B,delta_a):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # self.totalはソフトマックス関数の中の交差エントロピー\n",
    "        \n",
    "        self.DW1=np.zeros(W.shape[0])\n",
    "        self.DB1=np.array(np.sum(delta_a))\n",
    "        for s in range(W.shape[0]):\n",
    "            total=0\n",
    "            for i in range(self.A.shape[0]):\n",
    "                total+=delta_a[i]*X[i+s]\n",
    "            self.DW1[s]=total\n",
    "            \n",
    "        dX=np.zeros(X.shape[0])\n",
    "        for j in range(X.shape[0]):\n",
    "            total=0\n",
    "            for s in range(W.shape[0]):\n",
    "                if not(j-s<0 or j-s>self.A.shape[0]-1):\n",
    "                    total+=delta_a[j-s]*W[s]\n",
    "                else :\n",
    "                    total+=0\n",
    "            dX[j]=total\n",
    "\n",
    "        # 更新\n",
    "        self.B1 = B-self.lr*self.DB1\n",
    "        self.W1 = W-self.lr*self.DW1\n",
    "    \n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 22.],\n",
       "       [17., 23.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#　クラスを実行した結果、テキストが期待する値が返ってきている\n",
    "X=x\n",
    "W=w\n",
    "B=b\n",
    "\n",
    "SCA=SimpleConv1d_A(0.01)\n",
    "SCA.forward(X,W,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題５〜問題７は保留としたい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題8】学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　データの取り込みと処理を行う\n",
    "import numpy as np\n",
    "import math \n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　全結合クラス\n",
    "class FC_B:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2,initializer,optimizer):        \n",
    "        self.n_nodes1=n_nodes1\n",
    "        self.n_nodes2=n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.W1=self.initializer.W(self.n_nodes1,self.n_nodes2)\n",
    "        self.B1=self.initializer.B(self.n_nodes2)        \n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        \n",
    "        A=X@self.W1+self.B1\n",
    "        self.A=A\n",
    "        return A\n",
    "\n",
    "    \n",
    "    def backward(self, dA,Z):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "               \n",
    "        # 「3層目」\n",
    "        self.B2=np.sum(dA, axis=0)\n",
    "        self.W2=Z.T@dA\n",
    "        dZ=dA@self.W1.T\n",
    "        \n",
    "        #　参考で残す\n",
    "        #self.B1=self.B1-self.lr*self.B2\n",
    "        #self.W1=self.W1-self.lr*self.W2\n",
    "        \n",
    "        # 更新\n",
    "        self.B1,self.W1 = self.optimizer.update(self.B1,self.W1,self.B2,self.W2)\n",
    "    \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期化\n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1,n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_nodes2,)        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　最適化\n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self,B1,W1,B2,W2):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        self.B1=B1-self.lr*B2\n",
    "        self.W1=W1-self.lr*W2\n",
    "        \n",
    "        return self.B1,self.W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シグモイド関数のクラス\n",
    "class Sigmo_func:\n",
    "    \"\"\"\n",
    "    活性化関数のシグモイド関数クラス化\n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def Sigmo_func_f(self, A):\n",
    "        \"\"\"\n",
    "        シグモイド関数のフォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        self.A=A\n",
    "        Z=1/(1+np.exp(-A))\n",
    "        self.Z=Z\n",
    "        return Z\n",
    "       \n",
    "    def Sigmo_func_b(self, Z):\n",
    "        \"\"\"\n",
    "        シグモイド関数のバック\n",
    "        Parameters\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        sigmo1=(1-self.Sigmo_func_f(self.A))*self.Sigmo_func_f(self.A)\n",
    "        A=Z*sigmo1\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ソフトマックス関数のクラス\n",
    "class Softmax_func:\n",
    "    \"\"\"\n",
    "    活性化関数のソフトマックス関数のクラス化\n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def softmax_func_f(self, A):\n",
    "        \"\"\"\n",
    "        ソフトマックス関数\n",
    "        Parameters\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        Z=np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1) \n",
    "        self.Z=Z\n",
    "        return Z\n",
    "       \n",
    "    def softmax_func_b(self, mini_y_train):\n",
    "        \"\"\"\n",
    "        シグモイド関数\n",
    "        Parameters\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        # 交差エントロピー誤差\n",
    "        L = - np.sum(mini_y_train * np.log(self.Z)) / len(mini_y_train)\n",
    "        self.total=L\n",
    "        \n",
    "        # バックプロバケーション\n",
    "        A=(self.Z-mini_y_train)/len(self.Z)\n",
    "        self.A=A\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d_delete: \n",
    "    \n",
    "    def __init__(self,n_nodes1, n_nodes2,initializer,optimizer):        \n",
    "        self.n_nodes1=n_nodes1\n",
    "        self.n_nodes2=n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.W1=self.initializer.W(self.n_nodes1,self.n_nodes2)\n",
    "        self.B1=self.initializer.B(self.n_nodes1)        \n",
    "        self.optimizer = optimizer\n",
    "        self.A=np.zeros(self.W1.shape[0]-1) \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        A=np.zeros(196) \n",
    "        for j in range(X.shape[0]):\n",
    "            for i in range(196):\n",
    "                total=0\n",
    "                for s in range(self.W1.shape[1]):\n",
    "                    total+=X[j,:][i+s]*self.W1[j,s] \n",
    "                A[i]=(total+self.B1)\n",
    "            A=A.reshape(-1,196)\n",
    "            self.A=A\n",
    "            return A\n",
    "        \n",
    "        #A=np.zeros(self.W1.shape[0]-1) \n",
    "        #for i in range(self.W1.shape[0]-1):\n",
    "            #total=0\n",
    "            #for s in range(self.W1.shape[0]):\n",
    "                #total+=X[i+s]*self.W1[s]\n",
    "            #A[i]=(total+self.B1)\n",
    "            #self.A=A\n",
    "        #return A\n",
    "    \n",
    "    def backward(self,X,L):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # self.totalはソフトマックス関数の中の交差エントロピー\n",
    "        \n",
    "        self.DW1=np.zeros(self.W1.shape[0])\n",
    "        self.DB1=np.sum(L)\n",
    "        for j in range(X.shape[0]):\n",
    "            for s in range(self.W1.shape[0]):\n",
    "                total=0\n",
    "                for i in range(196):\n",
    "                    total+=L[j,i]*X[j,:][i+s]\n",
    "                self.DW1[s]=total        \n",
    "            \n",
    "        # 更新\n",
    "        self.B1 = self.B1-0.1*self.DB1\n",
    "        self.W1 = self.W1-0.1*self.DW1\n",
    "\n",
    "           \n",
    "        # 一旦、dxについて保留\n",
    "        #dX=np.zeros(X.shape[0])\n",
    "        #for j in range(X.shape[0]):\n",
    "            #total=0\n",
    "            #for s in range(self.W1.shape[0]):\n",
    "                #if not(j-s<0 or j-s>self.A.shape[0]-1):\n",
    "                    #total+=L[j-s]*self.self.W1[s]\n",
    "                #else :\n",
    "                    #total+=0\n",
    "            #dX[j]=total\n",
    "\n",
    "        # 更新\n",
    "        #self.B1 = self.B1-self.lr*self.DB1\n",
    "        #self.W1 = self.W1-self.lr*self.DW1\n",
    "    \n",
    "        #return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d: \n",
    "    \n",
    "    def __init__(self,n_nodes1, n_nodes2,initializer,optimizer):        \n",
    "        self.n_nodes1=n_nodes1\n",
    "        self.n_nodes2=n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.W1=self.initializer.W(self.n_nodes1,self.n_nodes2)\n",
    "        self.B1=self.initializer.B(1)        \n",
    "        self.optimizer = optimizer\n",
    "        self.A=np.zeros(self.W1.shape[0]-1) \n",
    "        \n",
    "    def forward(self, X):\n",
    "                \n",
    "        A=np.zeros(X.shape[1]-self.W1.shape[1]+1) \n",
    "        A1=A\n",
    "        for k in range(X.shape[0]-1):\n",
    "            A1=np.vstack([A1,A])\n",
    "        for j in range(X.shape[0]-1):\n",
    "            for i in range(X.shape[1]-self.W1.shape[1]+1-1):\n",
    "                total=0\n",
    "                for s in range(self.W1.shape[1]-1):\n",
    "                    total+=X[j,:][i+s]*self.W1[0,s]\n",
    "                A1[j,i]=total\n",
    "        A2=A1+self.B1\n",
    "        A2=A2.reshape(X.shape[0],-1)\n",
    "        self.A=A2\n",
    "        return A2\n",
    "    \n",
    "    def backward(self,X,dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # self.totalはソフトマックス関数の中の交差エントロピー\n",
    "        self.DB1=np.sum(dA)\n",
    "        \n",
    "        A=np.zeros(self.W1.shape[1]) \n",
    "        A1=A\n",
    "        for k in range(X.shape[0]-1):\n",
    "            A1=np.vstack([A1,A])\n",
    "        for j in range(X.shape[0]-1):\n",
    "            for s in range(self.W1.shape[1]-1):\n",
    "                total=0\n",
    "                for i in range(X.shape[1]-self.W1.shape[1]+1-1):\n",
    "                    total+=dA[j,i]*X[j,i+s]\n",
    "                A1[j,s]=total\n",
    "        A2=np.mean(A1,axis=0)\n",
    "        self.DW1=A2.reshape(1,-1)  \n",
    "        # 更新\n",
    "        self.B1 = self.B1-0.1*self.DB1\n",
    "        self.W1 = self.W1-0.1*self.DW1\n",
    "        \n",
    "        return self.W1\n",
    "\n",
    "           \n",
    "        # 一旦、dxについて保留\n",
    "        #dX=np.zeros(X.shape[0])\n",
    "        #for j in range(X.shape[0]):\n",
    "            #total=0\n",
    "            #for s in range(self.W1.shape[0]):\n",
    "                #if not(j-s<0 or j-s>self.A.shape[0]-1):\n",
    "                    #total+=L[j-s]*self.self.W1[s]\n",
    "                #else :\n",
    "                    #total+=0\n",
    "            #dX[j]=total\n",
    "\n",
    "        # 更新\n",
    "        #self.B1 = self.B1-self.lr*self.DB1\n",
    "        #self.W1 = self.W1-self.lr*self.DW1\n",
    "    \n",
    "        #return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier_A1():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self,ite_num, first_nodes,second_nodes,third_nodes,verbose = True):\n",
    "        self.verbose = verbose\n",
    "        self.ite_num=ite_num\n",
    "        self.first_nodes=first_nodes\n",
    "        self.second_nodes=second_nodes\n",
    "        self.third_nodes=third_nodes\n",
    "        self.loss = []\n",
    "        self.val_loss = []      \n",
    "\n",
    " \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\" \n",
    "        #　初期設定の処理\n",
    "        #  シグモイドを前提とした設定\n",
    "        SI1=SimpleInitializer(1/math.sqrt(X.shape[1]))\n",
    "        optimizer1=SGD(0.1)\n",
    "        self.FC1 = SimpleConv1d(1,56,SI1,optimizer1)\n",
    "        self.activation1=Sigmo_func()\n",
    "        \n",
    "        SI2=SimpleInitializer(1/math.sqrt(self.first_nodes))\n",
    "        optimizer2=SGD(0.1)\n",
    "        self.FC2 = FC_B(self.first_nodes,self.second_nodes,SI2,optimizer2)\n",
    "        self.activation2=Sigmo_func()\n",
    "        \n",
    "        SI3=SimpleInitializer(1/math.sqrt(self.second_nodes))\n",
    "        optimizer3=SGD(0.1)\n",
    "        self.FC3 = FC_B(self.second_nodes,self.third_nodes,SI3,optimizer3)\n",
    "        self.activation3=Softmax_func()\n",
    "        \n",
    "        \n",
    "        # 処理を行う\n",
    "        for _ in range(self.ite_num):\n",
    "            get_mini_batch = GetMiniBatch(X,y,batch_size=1)\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # フォワード\n",
    "                A1 = self.FC1.forward(mini_X_train)\n",
    "                Z1 = self.activation1.Sigmo_func_f(A1)\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.Sigmo_func_f(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.softmax_func_f(A3)\n",
    "                # バック\n",
    "                dA3 = self.activation3.softmax_func_b(mini_y_train)\n",
    "                dZ2 = self.FC3.backward(dA3,Z2)\n",
    "                dA2 = self.activation2.Sigmo_func_b(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2,Z1)\n",
    "                dA1 = self.activation1.Sigmo_func_b(dZ1)\n",
    "                dZ0 = self.FC1.backward(mini_X_train,dA1) # dZ0は使用しない\n",
    "              \n",
    "            self.loss.append(self.activation3.total)\n",
    "\n",
    "            if X_val is not None:                             \n",
    "                A1_val=self.FC1.forward(X_val)\n",
    "                Z1_val=self.activation1.Sigmo_func_f(self.FC1.forward(X_val))\n",
    "                A2_val=self.FC2.forward(Z1_val)\n",
    "                Z2_val=self.activation2.Sigmo_func_f(A2_val)\n",
    "                A3_val=self.FC3.forward(Z2_val)\n",
    "                Z3_val=self.activation3.softmax_func_f(A3_val) \n",
    "                dA3_val=self.activation3.softmax_func_b(y_val)            \n",
    "                self.val_loss.append(self.activation3.total)  \n",
    "            \n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"        \n",
    "        A1=self.FC1.forward(X)\n",
    "        Z1=self.activation1.Sigmo_func_f(self.FC1.forward(X))\n",
    "        A2=self.FC2.forward(Z1)\n",
    "        Z2=self.activation2.Sigmo_func_f(A2)                \n",
    "        A3=self.FC3.forward(Z2)\n",
    "        Z3=self.activation3.softmax_func_f(A3)\n",
    "        y_pred=np.argmax(Z3, axis=1)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [],
   "source": [
    "ite_num=1\n",
    "first_nodes=729\n",
    "second_nodes=200\n",
    "third_nodes=10\n",
    "SSNN1=ScratchSimpleNeuralNetrowkClassifier_A1(ite_num, first_nodes,second_nodes,third_nodes,verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSNN1.fit(X_train,y_train, X_val=None, y_val=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.051024293258231]"
      ]
     },
     "execution_count": 1302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSNN1.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
